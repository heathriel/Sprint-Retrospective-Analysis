{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06052a8",
   "metadata": {},
   "source": [
    "\n",
    "# Sprint Retrospective Analysis\n",
    "\n",
    "## Objective\n",
    "Analyze historical sprint data to identify areas for improvement and enhance future sprint planning.\n",
    "\n",
    "## Instructions\n",
    "Follow the steps provided in this notebook to load the data, preprocess it, perform exploratory data analysis, train a predictive model, and draw insights for sprint retrospectives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_dependencies",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install necessary libraries\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load the Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('sprint_data.csv')\n",
    "\n",
    "# Explore dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(data.head())\n",
    "print(\"\\nSummary statistics of the dataset:\")\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a274d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Data Preprocessing\n",
    "\n",
    "# Handle missing values (if any)\n",
    "data = data.dropna()\n",
    "\n",
    "# Select relevant columns\n",
    "relevant_columns = ['sprint_id', 'team_member', 'task_id', 'task_description', 'estimated_hours', 'actual_hours', 'completion_status']\n",
    "data = data[relevant_columns]\n",
    "\n",
    "# Create new feature for time difference\n",
    "data['time_diff'] = data['actual_hours'] - data['estimated_hours']\n",
    "\n",
    "# Display the first few rows of the preprocessed dataset\n",
    "print(\"First 5 rows of the preprocessed dataset:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f9ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Exploratory Data Analysis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot task completion rates\n",
    "completion_rate = data['completion_status'].value_counts(normalize=True) * 100\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=completion_rate.index, y=completion_rate.values)\n",
    "plt.title('Task Completion Rates')\n",
    "plt.xlabel('Completion Status')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()\n",
    "\n",
    "# Plot estimated vs actual time\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='estimated_hours', y='actual_hours', data=data, hue='completion_status')\n",
    "plt.title('Estimated vs Actual Time for Tasks')\n",
    "plt.xlabel('Estimated Hours')\n",
    "plt.ylabel('Actual Hours')\n",
    "plt.show()\n"
   ]
  },
    {
    "cell_type": "code",
   "execution_count": null,
   "id": "model_training",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Model Training and Evaluation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "data['team_member'] = label_encoder.fit_transform(data['team_member'])\n",
    "data['task_description'] = label_encoder.fit_transform(data['task_description'])\n",
    "data['completion_status'] = label_encoder.fit_transform(data['completion_status'])\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "data[['estimated_hours', 'actual_hours', 'time_diff']] = scaler.fit_transform(data[['estimated_hours', 'actual_hours', 'time_diff']])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X = data.drop(columns=['sprint_id', 'completion_status'])\n",
    "y = data['completion_status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a RandomForest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predictive_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Predictive Analysis and Insights\n",
    "\n",
    "# Use a subset of the test data as new data for prediction\n",
    "new_data = X_test.copy().reset_index(drop=True)\n",
    "new_data['predicted_completion_status'] = model.predict(new_data)\n",
    "\n",
    "# Analyze predictions\n",
    "new_data['predicted_completion_status'] = new_data['predicted_completion_status'].astype(int)\n",
    "new_data['team_member'] = label_encoder.inverse_transform(new_data['team_member'])\n",
    "new_data['task_description'] = label_encoder.inverse_transform(new_data['task_description'])\n",
    "print(new_data)\n",
    "\n",
    "# Generate insights\n",
    "for i, row in new_data.iterrows():\n",
    "    if row['predicted_completion_status'] == 0:  # Example status code for 'not completed'\n",
    "        print(f\"Task {row['task_id']} by team member {row['team_member']} is likely to be delayed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "In this analysis, we loaded and preprocessed sprint data, conducted exploratory data analysis to visualize task completion rates and time discrepancies, trained a machine learning model to predict sprint outcomes, and generated actionable insights based on the model's predictions. By leveraging these insights, teams can improve sprint planning, allocate resources more effectively, and enhance overall productivity.\n",
    "\n",
    "Further analysis can include trend analysis over multiple sprints and correlation analysis between different variables to gain deeper insights into the factors influencing sprint outcomes.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}